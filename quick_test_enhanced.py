#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•å¢å¼ºç‰ˆæœç´¢ç­–ç•¥
éªŒè¯è°ƒæ•´åçš„å‚æ•°èƒ½å¦è·å¾—æ›´å¤šæ•°æ®
"""

import os
import requests
from datetime import datetime, timedelta
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def quick_search_test():
    """å¿«é€Ÿæœç´¢æµ‹è¯•"""
    GITHUB_TOKEN = os.environ.get("GITHUB_TOKEN")
    
    if not GITHUB_TOKEN:
        print("âŒ æœªè®¾ç½®GITHUB_TOKEN")
        return
    
    headers = {
        "Authorization": f"token {GITHUB_TOKEN}",
        "Accept": "application/vnd.github.v3+json"
    }
    
    url = "https://api.github.com/search/repositories"
    
    # æµ‹è¯•ä¸åŒçš„æœç´¢ç­–ç•¥
    test_cases = [
        {
            "name": "LLMé¡¹ç›®-30å¤©-100æ˜Ÿ",
            "query": "LLM OR transformer stars:>100 created:2025-08-06..2025-09-05 is:public archived:false",
            "expected": "ä¸­ç­‰æ•°é‡"
        },
        {
            "name": "LLMé¡¹ç›®-30å¤©-50æ˜Ÿ", 
            "query": "LLM OR transformer stars:>50 created:2025-08-06..2025-09-05 is:public archived:false",
            "expected": "æ›´å¤šæ•°é‡"
        },
        {
            "name": "LLMé¡¹ç›®-30å¤©-20æ˜Ÿ",
            "query": "LLM OR transformer stars:>20 created:2025-08-06..2025-09-05 is:public archived:false",
            "expected": "å¤§é‡æ•°æ®"
        },
        {
            "name": "æœºå™¨å­¦ä¹ -90å¤©-20æ˜Ÿ",
            "query": "machine-learning OR deep-learning stars:>20 created:2025-06-08..2025-09-05 is:public archived:false",
            "expected": "å¤§é‡æ•°æ®"
        },
        {
            "name": "AIç»¼åˆ-90å¤©-10æ˜Ÿ",
            "query": "(artificial-intelligence OR AI OR machine-learning) stars:>10 created:2025-06-08..2025-09-05 is:public archived:false",
            "expected": "æµ·é‡æ•°æ®"
        }
    ]
    
    print("ğŸ§ª å¿«é€Ÿæœç´¢æµ‹è¯•")
    print("=" * 60)
    
    total_found = 0
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{i}. {test_case['name']}")
        print(f"   æŸ¥è¯¢: {test_case['query'][:50]}...")
        
        try:
            params = {
                "q": test_case["query"],
                "sort": "stars",
                "order": "desc",
                "per_page": 30  # åªå–å‰30ä¸ªæµ‹è¯•
            }
            
            response = requests.get(url, headers=headers, params=params)
            response.raise_for_status()
            
            data = response.json()
            total_count = data.get("total_count", 0)
            repos = data.get("items", [])
            
            print(f"   ç»“æœ: æ‰¾åˆ° {total_count} ä¸ªé¡¹ç›® (æ˜¾ç¤ºå‰{len(repos)}ä¸ª)")
            
            if repos:
                # æ˜¾ç¤ºå‰3ä¸ªé¡¹ç›®
                for j, repo in enumerate(repos[:3]):
                    print(f"      {j+1}. {repo['name']} - â­{repo['stargazers_count']} - {repo['owner']['login']}")
                
                total_found += len(repos)
            
        except Exception as e:
            print(f"   âŒ æœç´¢å¤±è´¥: {e}")
    
    print(f"\nğŸ“Š æµ‹è¯•æ€»ç»“:")
    print(f"   æµ‹è¯•ç”¨ä¾‹: {len(test_cases)} ä¸ª")
    print(f"   è·å¾—æ•°æ®: {total_found} æ¡")
    print(f"   å¹³å‡æ¯æ¬¡: {total_found/len(test_cases):.1f} æ¡")
    
    # é¢„æµ‹å…¨é‡æ”¶é›†æ•ˆæœ
    if total_found > 0:
        # å‡è®¾æˆ‘ä»¬æ‰§è¡Œ60æ¬¡æœç´¢ï¼ˆå¤šä¸ªå…³é”®è¯ç»„åˆï¼‰
        estimated_total = total_found * 4  # è€ƒè™‘ä¸åŒæ—¶é—´çª—å£å’Œæ’åº
        print(f"   é¢„è®¡å…¨é‡: {estimated_total} æ¡å€™é€‰")
        print(f"   é¢„è®¡æœ‰æ•ˆ: {estimated_total * 0.25:.0f} æ¡ (å‡è®¾25%æœ‰æ•ˆç‡)")
        
        if estimated_total * 0.25 >= 200:
            print("   âœ… å¯ä»¥è¾¾åˆ°200æ¡ç›®æ ‡!")
        else:
            print("   âš ï¸ éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ç­–ç•¥")

def test_ai_keywords():
    """æµ‹è¯•AIå…³é”®è¯çš„æœ‰æ•ˆæ€§"""
    print("\nğŸ” æµ‹è¯•AIå…³é”®è¯æœç´¢æ•ˆæœ")
    print("-" * 40)
    
    GITHUB_TOKEN = os.environ.get("GITHUB_TOKEN")
    
    if not GITHUB_TOKEN:
        print("âŒ æœªè®¾ç½®GITHUB_TOKEN")
        return
    
    headers = {
        "Authorization": f"token {GITHUB_TOKEN}",
        "Accept": "application/vnd.github.v3+json"
    }
    
    url = "https://api.github.com/search/repositories"
    
    # æµ‹è¯•ä¸åŒå…³é”®è¯çš„æ•ˆæœ
    keywords = [
        "LLM", "transformer", "GPT", "machine-learning", 
        "deep-learning", "computer-vision", "diffusion",
        "pytorch", "tensorflow", "AI", "artificial-intelligence"
    ]
    
    for keyword in keywords:
        try:
            # æœç´¢æœ€è¿‘90å¤©ï¼Œ20+æ˜Ÿæ ‡
            query = f"{keyword} stars:>20 created:2025-06-08..2025-09-05 is:public archived:false"
            
            params = {
                "q": query,
                "sort": "stars", 
                "order": "desc",
                "per_page": 5
            }
            
            response = requests.get(url, headers=headers, params=params)
            response.raise_for_status()
            
            data = response.json()
            total_count = data.get("total_count", 0)
            
            print(f"{keyword:20} : {total_count:4d} ä¸ªé¡¹ç›®")
            
        except Exception as e:
            print(f"{keyword:20} : æœç´¢å¤±è´¥ - {e}")

if __name__ == "__main__":
    quick_search_test()
    test_ai_keywords()
